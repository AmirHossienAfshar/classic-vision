\documentclass[a4paper,12pt]{article}
\usepackage{fullpage}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{geometry}
\usepackage{caption}
\usepackage{xepersian}
\usepackage{multicol}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{bidi} 
\usepackage{enumitem}

% Colors
\definecolor{titlepagecolor}{cmyk}{0.75,0.68,0.67,0.90} % Cover background
\definecolor{CustomAccent}{HTML}{2BAB8C} % Accent color for English text
%\definecolor{CustomBackground}{HTML}{1C1C1C} % Background for content pages
\definecolor{CustomBackground}{cmyk}{0.75,0.68,0.67,0.90}% Background for content pages

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\definecolor{codebg}{cmyk}{0.75,0.68,0.67,0.90} % same as CustomBackground
\definecolor{accent}{HTML}{2BAB8C} % same as CustomAccent
\definecolor{codegray}{rgb}{0.8,0.8,0.8}
\definecolor{codegreen}{rgb}{0.4,1,0.4}
\definecolor{codepurple}{rgb}{1,0.6,1}
\definecolor{keywordcolor}{rgb}{1,0.3,0.6}

\lstdefinestyle{darkstyle}{
	backgroundcolor=\color{codebg},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{keywordcolor},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize\color{white},
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=10pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4,
	frame=single,
	rulecolor=\color{accent}
}

\lstset{style=darkstyle}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







% Persian and Latin fonts
\settextfont{Vazir.ttf}[BoldFont = Vazir-Bold.ttf, Path = fonts/]
\setlatintextfont{Times New Roman}

% Line spacing
\renewcommand{\baselinestretch}{1.2}
\renewcommand{\thesection}{\arabic{section})}

\color{white}


% Homework number
\newcommand{\HomeworkNumber}{1}

% Cover-only settings
\pagenumbering{gobble}

% ---------- COVER PAGE ----------
\begin{document}
	\begin{latin}
		\begin{titlepage}
			\newgeometry{top=1in,bottom=1in,right=0in,left=0in}
			\thispagestyle{empty}
			\pagecolor{titlepagecolor}
			\color{white}
			\begin{center}
				\vspace*{\stretch{1}}
				
				{\fontsize{48}{0}\bfseries\selectfont \color{CustomAccent} INTRODUCTION TO COMPUTER VISION}
				
				\vskip 1.5\baselineskip
				{\fontsize{24}{0}\selectfont PROJECT DOCUMENTATION}
				
				\vspace*{\stretch{2}}
				\adjincludegraphics[width=1\paperwidth]{assets/cover2.png}
				
				\vspace*{\stretch{2}}
				{\fontsize{20}{0}\selectfont \color{CustomAccent}
					Ferdowsi University of Mashhad \\
					Department of Computer Engineering
				}
				
				\vskip 1.5\baselineskip
				{\Large SPRING 2025}
				
				\vspace*{\stretch{1}}
			\end{center}
		\end{titlepage}
	\end{latin}
	
	% ---------- RESET PAGE SETTINGS ----------
	\clearpage
	\nopagecolor
	\pagecolor{CustomBackground}
	\color{white}
	\newgeometry{top=1in,bottom=1in,left=1in,right=1in}
	\pagenumbering{arabic}
	
	% ---------- HEADER (PERSIAN) ----------
	\hrule \medskip
	\begin{minipage}{0.295\textwidth}
		\raggedleft \color{CustomAccent}
		مبانی بینایی کامپیوتر\\
		دانشگاه فردوسی مشهد\\
		گروه مهندسی کامپیوتر
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\centering 
		\includegraphics[scale=0.3]{assets/fum-logo.png}
	\end{minipage}
	\begin{minipage}{0.295\textwidth} \color{CustomAccent}
		داکیومنت پروژه \\
		دکتر طاهری نیا \\
		بهار 1404
	\end{minipage}
	\medskip\hrule
	\bigskip	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|}
			\hline
			\textbf{نام و نام خانوادگی} & \textbf{شماره دانشجویی} \\
			\hline
			امیرحسین افشار & 4012262196 \\
			\hline
		\end{tabular}
	\end{table}
	
\hline
%	\begin{figure}[h]
	%		\centering
	%		\includegraphics[scale=0.35]{assets/template.png}
	%		\caption*{\textcolor{CustomAccent}{k-means}}
	%	\end{figure}

	
	\section{سوال اول: معمای داوینچی}
	 در ابتدا برای حل پازل، عملیات denoising را برای تصویر
$processed\_img\_part\_1.jpg$
انجام شد. بدین منظور، از هیستوگرام تصویر بهره گرفته شده است \textsuperscript{[1]} ؛ هیستوگرام تصویر با سطوح خاکستری، بر اساس نرمال کردن میزان پیکسل های با شدت بین 0 تا 255 ساخته می شود تا شکل 
function distribution probability
بدست آید.
 پلات زیر، بیانگر هیستوگرام برای تصویر نویزی شماره 1 است:

\begin{figure}[h]
		\centering
		\includegraphics[scale=0.35]{assets/plot1.png}
		\caption{\textcolor{CustomAccent}{پلات هیستوگرام تصویر نویزی شماره 1}}
	\end{figure}
	
	این شکل، بیان می کند که تعداد پیکسل ها با مقدار نزدیک به صفر و مقدار نزدیک به 255 بسیار زیاد است. همچنین هیستوگرام احتمال قابل انتظار برای تصاویر نویزی با نوع نویز نمک فلفل به شکل زیر است:
	
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot2.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام قابل انتظار برای تصاویر نویزی نمک و فلفل}}
\end{figure}

\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} Asoke Nath: Image Denoising Algorithms: A Comparative Study of Different Filtration Approaches Used in Image Restoration
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}

با مقایسه شکل 1 و 2 می توان نتیجه گرفت که نویز تصویر شماره 1 از نوع نمک و فلفل می باشد. بنابراین، برای denoise کردن تصویر، بهترین گزینه، استفاده از فیلتر median می باشد. 
شایان ذکر است که در عملیات denoise کردن تصویر برای اطمینان بیشتر از نوع نویز، از انواع فیلترها استفاده شد که به شرح زیر هستند:

\begin{table}[ht]
	\centering
	\begin{latin}
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{Category} & \textbf{Filter Name} & \textbf{Function} \\
		\hline
		Smoothing Filters  & Box Filter              & \texttt{denoise\_box\_filter} \\
		& Gaussian Filter         & \texttt{denoise\_gaussian\_filter} \\
		\hline
		Statistical Filters & Median Filter           & \texttt{denoise\_median\_filter} \\
		& Max Filter              & \texttt{denoise\_max\_filter} \\
		& Min Filter              & \texttt{denoise\_min\_filter} \\
		\hline
		Advanced Filters   & Bilateral Filter        & \texttt{denoise\_bilateral\_filter} \\
		& Non-Local Means         & \texttt{denoise\_nl\_means} \\
		& Wavelet Filter          & \texttt{denoise\_wavelet\_filter} \\
		& Total Variation Filter  & \texttt{denoise\_total\_variation} \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{انواع فیلتر ها و توابع denoising به کار گرفته شده}
\end{table}


همانطور که از شکل 1 انتظار می رفت، بهترین عملکرد خروجی با استفاده از فیلتر میانه یا همان median بدست می آید. در نهایت، برای نهایی کردن بهترین خروجی با استفاده از فیلتر میانه، دو روش پیگیری شد:
\begin{enumerate}
	\item 
	استفاده از چند مرحله فیلتر median با ابعاد یکسان
	\item 
	استفاده از یک فیلتر median با کرنل بزرگتر
\end{enumerate}
روش اول، به طور کلی برای حفظ جزئیات تصویر مناسب تر است؛ زیرا هرگونه کرنل بزرگ  با ریسک از دست دادن جزئیات همراه است. از طرفی، ممکن است که همگرا شدن تصویر پس از اعمال چند بار فیلتر میانه، به کندی پیش رود و حتی برخی نویز ها در تصویر باقی بمانند که این مشکل، در روش دوم وجود ندارد. 

در نهایت، با توجه به مسئله که تنها نیاز است یک متن از تصویر استخراج شود (و حفظ سایر جزئیات دارای اهمیت کمتری است،) از روش دوم استفاده شد.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot4.png}
	\caption{\textcolor{CustomAccent}{شکل نهایی تصویر denoise شده}}
\end{figure}

\pagebreak

همچنین شایان ذکر است که برای درک بهتر نویز، از حوزه ی فرکانس نیز کمک گرفته شد
 \textsuperscript{[1]}  که بتوان نوع نویز را حدس زد و در نهایت با استفاده از فیلتر های notch و یا band-pass و یا band-reject از نویز تصویر کاست. شکل سوم بیانگر این موضوع است.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot3.png}
	\caption{\textcolor{CustomAccent}{تصویر شماره 1 در حوزه فرکانس}}
\end{figure}

با توجه به magnitude تصویر در حوزه فرکانس، نمی توان نویز خاصی را قائل شد که نهایتا، همان فیلتر میانه که از هیستوگرام تصویر درک شده بود، استفاده شد.


\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} Digital Image Processing By Gonzalez 2nd Edition 2002, chapter 4.2
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}
%
%تبصره: برای کاهش حجم فایل ipynb برای پلاک کردن تصاویر، از figure هایی با ابعاد کوچک استفاده شده است که به ناچار تصاویر را sample down می کند؛ در عین حال، کلیت حل مسئله همچنان صحیح است. همچنین در تابع 
%
%\begin{latin}
%	\begin{lstlisting}[language=Python, caption={extract feature function}]
%def plote_images(images: list[np.ndarray], titles: list[str] = None, cmap: str = 'gray', figsize: tuple = (10, 5))
%...
%	\end{lstlisting}
%\end{latin}
%میتوان با انتخاب figsize بزرگتر، عملکرد هر کدام از فیلتر ها را به شکل واضح تری دید.
\pagebreak
\begin{itemize}
\item 
بخش دوم
\end{itemize}

برای این بخش باید تصویر 
$processed\_img\_part\_2.jpg$
اصلاح می شد. بدین منظور و در ابتدا برای تشخیص نویز، از انرژی و magnetude تصویر استفاده شد؛ زیرا تصویر کاملا پوشیده از نویز بود و پیش بینی نوع نویز را سخت می کرد. همچنین برای درک بهتر کلیت تصویر، با حذف فرکانس های بالا، یک تخمین از کلیت تصویر به دست آمده است. برای این منظور، پلات زیر رسم شده است:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{assets/plot9.png}
	\caption{\textcolor{CustomAccent}{پیش بینی نوع نویز در تصویر دوم}}
\end{figure}


با دقت کردن به لگاریتم power در پلات (شکل شماره 5) متوجه یک حلقه می شویم که با الگوی سینوسی نویز در تصویر در حوزه مکان تطابق دارد. برای درک بهتر این نویز، به طور مستقل برای تصویر در حوزه فرکانس magnitude و phase رسم شده است که به شکل زیر است:


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/plot10.png}
	\caption{\textcolor{CustomAccent}{تصویر دوم در حوزه فرکانس}}
\end{figure}

که ایده اولیه را تایید می کند. بدین منظور، تنها و به سادگی با ساختن یک فیلتر band-reject در حوزه فرکانس، این مشکل حل شده و تصویر نهایی ساخته می شود.

\pagebreak


\begin{itemize}
	\item 
	بخش سوم
\end{itemize}
برای بخش سوم از پازل، باید تصویر اصلی را از 5 زیر تصویر reconstruct می کردیم. بدین منظور، تصاویر در ابتدا و در کنار یکدیگر plot شده اند:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/plot5.png}
	\caption{\textcolor{CustomAccent}{زیرتصاویر بخش سوم پازل}}
\end{figure}


همچنین ابعاد هر کدام از تصاویر در جدول زیر بیان شده است:

\begin{table}[h!]
	\centering
	\begin{latin}
	\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Image File} & \textbf{Width (px)} & \textbf{Height (px)} \\
		\hline
		processed\_img\_part\_3\_Level\_0.jpg & 1796 & 1201 \\
		processed\_img\_part\_3\_Level\_1.jpg & 898  & 601  \\
		processed\_img\_part\_3\_Level\_2.jpg & 449  & 301  \\
		processed\_img\_part\_3\_Level\_3.jpg & 225  & 151  \\
		processed\_img\_part\_3\_Level\_4.jpg & 113  & 76   \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{ابعاد زیر تصاویر در بخش سوم پازل}
\end{table}

با توجه به جدول شماره 2 که بیانگر ابعاد پازل است، میتوان متوجه شد که در هر مرحله با تقریب هم طول و هم عرض تصویر نصف می شود. این موضوع، وجود نوعی pyramid را در ذهن تداعی می کند \textsuperscript{[1]}.
 این موضوع، در زیربخش سوم فصل هفتم کتاب گونزالس
 \textsuperscript{[2]}
  به این شکل آمده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{assets/pyramids.png}
	\caption{\textcolor{CustomAccent}{انواع pyramid ها: کتاب گونزالس، زیربخش سوم فصل هفتم}}
\end{figure}




\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \\
				\textsuperscript{[2]} Digital Image Processing By Gonzalez 2nd Edition 2002, chapter 7.3
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}
 

\pagebreak

برای درک بهتر هرم، هیستوگرام احتمال برای هر کدام از زیر تصاویر رسم شده است:


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/plot6.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام در هرم}}
\end{figure}

نمودار هیستوگرام نرمال‌شده‌ی هرم، توزیع آماری مقدارهای باقیمانده در هر سطح از هرم را نمایش می‌دهد. در فرآیند ساخت هرم، هر تصویر در یک سطح با نسخه‌ی بزرگ‌ نمایی ‌شده ‌ی تصویر سطح بعدی کم می‌شود، و نتیجه این اختلاف، تصویر باقیمانده‌ای است که تنها حاوی اطلاعات لبه‌ ها، جزییات کوچک است. برای نمایش بهتر این اطلاعات، از یک آفست استفاده شده و همچنین نرمال سازی انجام شده است. در تایید این موضوع، از تبدیل به حوزه فوریه و نمایش فاز هر کدام از زیر تصاویر نیز استفاده شده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/plot7.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام در هرم}}
\end{figure}
 همانطور که مشخص است، لبه های کوچک در سطوح بالا، دارای فاز یکنواخت تری هستند و هرچه به لایه های پایین تر می رویم، این یکنواختی کمتر می شود و تغییرات فرکانس وضوح می یابند.

با دقت به این هیستوگرام، (و همچنین زیرتصاویر ارائه شده در شکل پنجم) میتوان نتیجه گرفت که هرم از نوع لاپلاسی است؛ هر مرحله از downsample شدن تصویر و محاسبه اختلاف با لایه قبلی محاسبه می شود که برای ساختن تصویر اصلی، کافیست معکوس این کار را انجام دهیم.


\pagebreak

برای درست کردن تصویر، در ابتدا تلاش شد که با طی کردن فرایند به شکل معکوس، تصویر اصلی ساخته شود، اما تصویر خروجی شامل کیفیت مناسب نبود. بدین منظور، از تابع resize از کتابخانه cv2 استفاده شد که به صورت خطی تصویر را تغییر سایز می دهد. همچنین، برای بهبود نهایی، مقادیر grayscale به uint8 تغییر یافته اند؛ به عبارتی، مقادیر قبلی سطوح خاکستری با این کار، به بازه (0, 255) گسترش یافتند که باعث بهبود کنتراست شد.
تصویر نهایی ساخته شده نیز در شکل 9 آمده شده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{assets/plot8.png}
	\caption{\textcolor{CustomAccent}{تصویر نهایی ساخته شده از زیرتصاویر}}
\end{figure}


\pagebreak
\section{پروژه دوم: تصاویرنویزی/غیرنویزی}
در این پروژه، هر دو روش یادگیری عمیق و بینایی ماشین کلاسیک پیاده سازی شده است. در ابتدا به تفصیل، روش یادگیری عمیق توضیح داده می شود:

\section{یادگیری عمیق در پروژه دوم}


در ابتدا، برای پیاده سازی سیستم تشخیص نویز ها، این نیاز دیده میشد که دیتاست های در اختیار قرار گرفته ، دیتاست های کوچکی هستند و برای روش های ml و یا dl مناسب نیستند. به گونه ای که حتی با augment کردن داده ها و پیاده سازی بر روی مدل های pre-trained و با fine tune کردن آنها نیز، کفایت نمیکرد.  بنابراین، با بررسی دیتاست های قرار داده شده کشاورزی که از نوع برگ درختان هستند، دیتاست های کاندیدا از وبسایت kaggle به شرح زیر هستند:
\begin{enumerate}
	\begin{LTR}
		\begin{latin}
			\item https://www.kaggle.com/datasets/ichhadhari/leaf-images
			\item https://www.kaggle.com/datasets/mdwaquarazam/agricultural-crops-image-classification/data
			\item https://www.kaggle.com/datasets/alexo98/leaf-detection
		\end{latin}
	\end{LTR}
\end{enumerate}

که طبق بررسی انجام شده، بهترین و مشابه ترین دیتاست، مربوط به دیتاست leaf-detection است. 
دقت شود که این موضوع که دیتاست ها باید برای استفاده این پروژه به شکل کاملی شخصی سازی شوند (به عنوان مثال، نویز به تصاویر اضافه شود) کاملا واضح است و از ابتدا صرفا به دنبال دیتاست هایی صرفا با زمینه مرتبط بودم و سپس دیتاست ها را به شکل مناسبی برای استفاده از این پروژه شخصی سازی کردم. مجددا تاکید میشود که دیتاست انتخاب شده، صرفا انواع برگ های گوناگون بوده است و هیچ هدفی از نویز/دینویز کردن تصاویر در این دیتاست دنبال نشده است. 

بررسی دیتاست آورده شده:

با توجه به این که این دیتاست، صرفا شامل تصاویری از برگ های 10 نوع درخت هندی هستند، بدون توجه به لیبل های آن برگ ها، و صرفا با در نظر گرفتن همه آنها از یک نوع، (همگی را به شکل یکسان و «برگ» در نظر گرفتم) به آنها انواع گوناگونی از نویز ها پیاده سازی کردم. در ابتدا، نویزهای تکی، یعنی :

سپس انواع نویز های دو تایی (تمامی جایگشت ها لحاظ نشده است؛ به علت محدودیت پردازشی گوگل کولب به 16 گیگ حافظه رم، بیش از این نوع نمیتوان جایگشت های مختلفی از نویز در نظر گرفت):

\pagebreak

\begin{table}[h]
	\centering
	\begin{latin}
	\begin{tabular}{|c|c|l|}
		\hline
		\textbf{No.} & \textbf{Combinations} & \textbf{Noise Type} \\
		\hline
		1 & 1 & Gaussian \\
		\hline
		2 & 1 & Salt \& Pepper \\
		\hline
		3 & 1 & Poisson \\
		\hline
		4 & 1 & Speckle \\
		\hline
		5 & 1 & Uniform \\
		\hline
		6 & 2 & Gaussian + Salt \& Pepper \\
		\hline
		7 & 2 & Gaussian + Poisson \\
		\hline
		8 & 2 & Gaussian + Speckle \\
		\hline
		9 & 2 & Gaussian + Uniform \\
		\hline
		10 & 2 & Salt \& Pepper + Speckle \\
		\hline
		11 & 2 & Salt \& Pepper + Uniform \\
		\hline
		12 & 2 & Poisson + Speckle \\
		\hline
		13 & 2 & Poisson + Uniform \\
		\hline
		14 & 2 & Speckle + Uniform \\
		\hline
		15 & 3 & Gaussian + Salt \& Pepper + Speckle \\
		\hline
		16 & 3 & Gaussian + Poisson + Uniform \\
		\hline
		17 & 3 & Salt \& Pepper + Speckle + Uniform \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{لیست انواع نویز های پیاده شده}
\end{table}
	

\pagebreak


\section{پروژه سوم: ادغام تصاویر پزشکی}
در این پروژه، ابتدا پیاده‌سازی با استفاده از روش‌های کلاسیک انجام شده و جزئیات مربوط به آن به‌طور کامل توضیح داده شده است. گام مشترک میان هر دو روش، پروفایل دیتا است.
در ابتدا باید بر روی دیتاست عملیات پروفایل کردن دیتا انجام میشد که بررسی شود دیتاست تصاویر به شکل ct (که به شکلی هستند که استخوان ها را به رنگ سفید نمایش می دهند) با تصاویر mri از نظر سایز، فرمت، طول و عرض تصویر و نسبت طول به عرض با یکدیگر تطابق دارند یا خیر. بدین منظور، نتیجه این پروفایل کردن در زیر قابل مشاهده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/3.2.png}
	\caption{\textcolor{CustomAccent}{نتیجه پروفایل دیتا}}
\end{figure}
(شایان ذکر است که شاید گمان شود که برای این دیتاست کوچک، نیازی به پروفایل کردن دقیق دیتا نبوده و صرفا یک مشاهده کوچک بر روی 8 زوج عکس، کفایت میکند، اما روش ارائه شده برای هرتعداد جفت عکس ارائه شده قابل اجراست و مرحله ابتدایی الزامی هر پروژه ای محسوب میشود.)

\section*{راه حل با روش های بینایی کلاسیک}

همانطور که در اسلاید های درسی داشتیم:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{assets/3.1.png}
	\caption{\textcolor{CustomAccent}{نحوه ادغام دو نوع تصویر مختلف}}
\end{figure}

باید pyramid هایی از هر دو نوع تصویر تهیه کنیم. در ابتدا ویژگی هایی که هر سطح از این pyramid ها شامل می شوند، به شکل زیر بیان می شود:
\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{سطح} & \textbf{اندازه تصویر} & \textbf{فرکانس} & \textbf{ویژگی‌های استخراج‌شده} \\
		\hline
		سطح ۰ & اندازه کامل & فرکانس بالا & جزئیات ریز (لبه‌ها، بافت، نویز) \\
		\hline
		سطح ۱ & نصف اندازه & فرکانس متوسط & لبه‌های بزرگ‌تر، اشکال \\
		\hline
		سطح ۲ & یک‌چهارم اندازه & فرکانس پایین & نواحی صاف، روشنایی کلی \\
		\hline
		سطح N (بالا) & بسیار کوچک & فرکانس بسیار پایین & ساختار کلی، سایه‌روشن نرم \\
		\hline
	\end{tabular}
	\caption{ساختار سطوح در هرم تصویری}
\end{table}
این قانون در رابطه با هر دو نوع هرم گوسی و لاپلاسی صدق می کند. (این دو هرم در نوع نمایششان با یکدیگر متفاوت هستند) .
در نهایت، مورد دیگری که باید بحث شود نحوه ادغام است که به این شکل چندین روش می توان به کار برد:
\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Fusion Rule} & \textbf{عملکرد} & \textbf{ویژگی‌های حفظ‌شده} \\
		\hline
		Average (mean) & ترکیب برابر دو تصویر & اطلاعات متعادل \\
		\hline
		Min & انتخاب مقدار کمینه هر پیکسل & ویژگی‌های تیره \\
		\hline
		Max & انتخاب مقدار بیشینه هر پیکسل & ویژگی‌های روشن \\
		\hline
		Max-Abs & انتخاب پیکسلی با بیشترین قدرمطلق & لبه‌های قوی با فرکانس بالا \\
		\hline
		Energy-Max & انتخاب پیکسل از تصویری با انرژی محلی بالاتر & بافت، واریانس محلی \\
		\hline
		Saliency-Based & انتخاب پیکسل با لبه بیشتر & ساختارهای برجسته \\
		\hline
		Weighted (static) & میانگین وزنی با وزن‌های دستی & تاثیر قابل تنظیم \\
		\hline
		Weighted (adaptive) & وزن‌دهی بر اساس انرژی & ترکیب تطبیقی \\
		\hline
		PCA-Based & تقسیم تصویر به مؤلفه‌های اصلی & ساختارهای همبسته \\ 
		\hline
	\end{tabular}
	\caption{قوانین مختلف ادغام تصویر و ویژگی‌های حفظ‌شده}
\end{table}

پارامتر بعدی که باید بررسی شود، عمق این pyramid ها می باشد. به طور کلی، با توجه به اینجا:
\begin{latin}
	\begin{itemize}
		\item \href{https://ieeexplore.ieee.org/document/1095851}{The Laplacian Pyramid as a Compact Image Code}
	\end{itemize}
\end{latin}
اشاره شده است که برای تهیه هر هرمی، میتوان از الگوی زیر تبعیت کرد:
\[
\text{max\_levels} = \left\lfloor \log_2\left(\min(H, W)\right) \right\rfloor
\]
که با توجه به تصویر ورودی 256 * 256 می توان هرم را به حداکثر 8 سطح تقسیم کرد. 


\pagebreak
\section*{راه حل با روش های یادگیری عمیق}

به‌عنوان مطالعه ی تکمیلی، روش‌های مبتنی بر یادگیری عمیق را نیز بررسی کردم. به طور خاص مقاله ای که مطالعه کردم در اینجا قرار دارد:

\begin{latin}
\begin{itemize}
\item \href{https://arxiv.org/html/2506.15218v1}{DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder}
\end{itemize}
\end{latin}
 
 روش های کلاسیکی که پیاده سازی شده است، صرفا شامل ساختار های هرم بودند و در نهایت در پیشرفته ترین مدل های خود، از ویولت استفاده می کردند که مشکل بزرگی داشتند:
 یا تصویر نهایی به شکل زیادی smooth می شود و یا جزئیات هر دو منبع ورودی را نمیتوان نگه داشت.
 این دو مورد انگیزه هایی بودند که برای حل این مسئله شبکه های عمیق سوق داده شده اند.
 
 
 مرحله‌ی اول بر پایه‌ی DDPM طراحی شده است؛ مدلی که هدف آن، یادگیری معکوس‌سازی یک forward noise process به‌صورت مرحله‌به‌مرحله است. برخلاف کاربردهای معمول که در آن‌ها تصویر نهایی از نویز تصادفی تولید می‌شود، در این‌جا DDPM به‌عنوان ابزاری برای استخراج  map feature ‌های با کیفیت بالا و در مقیاس‌های مختلف از هر نوع تصویر MRI و CT به کار گرفته شده است.
 
 در این چارچوب، برای هر مدالیته یک diffusion model مبتنی بر UNet به‌صورت جداگانه آموزش داده شده است. هدف این مرحله بازسازی تصویر نیست، بلکه embedding کردن اطلاعات هر مدالیته در یک فضای بازنمایی عمیق و سلسله‌مراتبی است که بتواند ساختارهای مهم تصویر را به‌خوبی نمایش دهد.
 
 ویژگی‌هایی که در این مرحله استخراج می‌شوند، نقش نوعی سوپروایزر را برای نوع تصویر خود ایفا می‌کنند؛ به این معنا که مدل MRI در شناسایی ویژگی‌های مرتبط با soft tissue تخصص دارد، در حالی که مدل CT تمرکز بیشتری روی ساختارهای استخوانی دارد.
 
 در مجموع، این مرحله مانند یک preprocessor هوشمند عمل می‌کند که به‌جای استفاده از feature extractorهای سطحی و سنتی، از encoderهایی بهره می‌گیرد که با فرایند diffusion آموزش دیده‌اند و می‌توانند فیچر ‌هایی دقیق ارائه دهند.
 
 پس از استخراج deep feature
 ها از هر دو مدالیته، مرحله‌ی دوم با نام 
 \begin{latin}
DFFM (Diffusion Feature Fusion Model) 
 \end{latin}
 
 
 وظیفه‌ی ادغام واقعی اطلاعات را بر عهده می‌گیرد. برخلاف روش‌های ساده‌ای مانند میانگین‌گیری یا روی هم قرار دادن مستقیم ویژگی‌ها، در این‌جا فرایند fusion با استفاده از دو ماژول مجزا و هدفمند انجام شده است.
 

بخشی از کدهایی که از این مقاله که شامل معماری مدل اصلی بود در فایل پایتونی ام قرار دادم.
قصد داشتم از این مدل یک inference انجام دهم تا با روش های کلاسیک مقایسه کنم؛ اما در نهایت تنها به بیان مطالعات، درک و برداشت خود از این نوع شبکه‌های عمیق بسنده کردم؛ زیرا  یتاست‌های غنی و همچنین مدل‌ ها و مقالات متعددی وجود دارند که بر روی همین زمینه فعالیت کرده اند و منبع خوبی برای یادگیری هستند.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\pagebreak
	
	در ابتدا، به کمک کتابخانه 
	$cv2$
	تابع زیر را برای دریافت فیچرها تکمیل کردیم. 
	
	\begin{latin}
		\begin{lstlisting}[language=Python, caption={extract feature function}]
			def extract_features(image_path)
			# input is an image and the ouput is an array of features.
		\end{lstlisting}
	\end{latin}
	
	


	\begin{figure}[ht]
		\centering
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{another caption}}
		\end{minipage}
		\hfill
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{caption new}}
		\end{minipage}
		\vspace{1em}
		\hfill
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{caption new}}
		\end{minipage}
		\vspace{1em}
	\end{figure}
	
	
	
\clearpage
\section*{منابع}

\begin{LTR}
	\begin{latin}
		\begin{enumerate}[left=0pt,labelsep=5pt,itemsep=0pt,parsep=0pt,topsep=0pt]
			\item Image Denoising Algorithms: A Comparative Study of Different Filtration Approaches Used in Image Restoration.  \url{https://ieeexplore.ieee.org/abstract/document/6524379/}
			\item Digital Image Processing By Gonzalez 4th  \url{https://elibrary.pearson.de/book/99.150005/9781292223070}
			\item Automatic identification of noise in ice images using statistical features \url{https://www.researchgate.net/figure/Simple-pattern-classifier-to-identify-noise-types-of-Gaussian-Speckle-and -Salt-Pepper_tbl1_258714501}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			
			
			% below are dummy
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			
		\end{enumerate}
	\end{latin}
\end{LTR}



\end{document}
