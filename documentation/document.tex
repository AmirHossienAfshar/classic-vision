\documentclass[a4paper,12pt]{article}
\usepackage{fullpage}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{geometry}
\usepackage{caption}
\usepackage{xepersian}
\usepackage{multicol}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{bidi} 
\usepackage{enumitem}

% Colors
\definecolor{titlepagecolor}{cmyk}{0.75,0.68,0.67,0.90} % Cover background
\definecolor{CustomAccent}{HTML}{2BAB8C} % Accent color for English text
%\definecolor{CustomBackground}{HTML}{1C1C1C} % Background for content pages
\definecolor{CustomBackground}{cmyk}{0.75,0.68,0.67,0.90}% Background for content pages

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\definecolor{codebg}{cmyk}{0.75,0.68,0.67,0.90} % same as CustomBackground
\definecolor{accent}{HTML}{2BAB8C} % same as CustomAccent
\definecolor{codegray}{rgb}{0.8,0.8,0.8}
\definecolor{codegreen}{rgb}{0.4,1,0.4}
\definecolor{codepurple}{rgb}{1,0.6,1}
\definecolor{keywordcolor}{rgb}{1,0.3,0.6}

\lstdefinestyle{darkstyle}{
	backgroundcolor=\color{codebg},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{keywordcolor},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize\color{white},
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=10pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4,
	frame=single,
	rulecolor=\color{accent}
}

\lstset{style=darkstyle}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







% Persian and Latin fonts
\settextfont{Vazir.ttf}[BoldFont = Vazir-Bold.ttf, Path = fonts/]
\setlatintextfont{Times New Roman}

% Line spacing
\renewcommand{\baselinestretch}{1.2}
\renewcommand{\thesection}{\arabic{section})}

\color{white}


% Homework number
\newcommand{\HomeworkNumber}{1}

% Cover-only settings
\pagenumbering{gobble}

% ---------- COVER PAGE ----------
\begin{document}
	\begin{latin}
		\begin{titlepage}
			\newgeometry{top=1in,bottom=1in,right=0in,left=0in}
			\thispagestyle{empty}
			\pagecolor{titlepagecolor}
			\color{white}
			\begin{center}
				\vspace*{\stretch{1}}
				
				{\fontsize{48}{0}\bfseries\selectfont \color{CustomAccent} INTRODUCTION TO COMPUTER VISION}
				
				\vskip 1.5\baselineskip
				{\fontsize{24}{0}\selectfont PROJECT DOCUMENTATION}
				
				\vspace*{\stretch{2}}
				\adjincludegraphics[width=1\paperwidth]{assets/cover2.png}
				
				\vspace*{\stretch{2}}
				{\fontsize{20}{0}\selectfont \color{CustomAccent}
					Ferdowsi University of Mashhad \\
					Department of Computer Engineering
				}
				
				\vskip 1.5\baselineskip
				{\Large SPRING 2025}
				
				\vspace*{\stretch{1}}
			\end{center}
		\end{titlepage}
	\end{latin}
	
	% ---------- RESET PAGE SETTINGS ----------
	\clearpage
	\nopagecolor
	\pagecolor{CustomBackground}
	\color{white}
	\newgeometry{top=1in,bottom=1in,left=1in,right=1in}
	\pagenumbering{arabic}
	
	% ---------- HEADER (PERSIAN) ----------
	\hrule \medskip
	\begin{minipage}{0.295\textwidth}
		\raggedleft \color{CustomAccent}
		مبانی بینایی کامپیوتر\\
		دانشگاه فردوسی مشهد\\
		گروه مهندسی کامپیوتر
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\centering 
		\includegraphics[scale=0.3]{assets/fum-logo.png}
	\end{minipage}
	\begin{minipage}{0.295\textwidth} \color{CustomAccent}
		داکیومنت پروژه \\
		دکتر طاهری نیا \\
		بهار 1404
	\end{minipage}
	\medskip\hrule
	\bigskip	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|}
			\hline
			\textbf{نام و نام خانوادگی} & \textbf{شماره دانشجویی} \\
			\hline
			امیرحسین افشار & 4012262196 \\
			\hline
		\end{tabular}
	\end{table}
	
\hline
%	\begin{figure}[h]
	%		\centering
	%		\includegraphics[scale=0.35]{assets/template.png}
	%		\caption*{\textcolor{CustomAccent}{k-means}}
	%	\end{figure}

	
	\section{سوال اول: معمای داوینچی}
	 در ابتدا برای حل پازل، عملیات denoising را برای تصویر
$processed\_img\_part\_1.jpg$
انجام شد. بدین منظور، از هیستوگرام تصویر بهره گرفته شده است \textsuperscript{[1]} ؛ هیستوگرام تصویر با سطوح خاکستری، بر اساس نرمال کردن میزان پیکسل های با شدت بین 0 تا 255 ساخته می شود تا شکل 
function distribution probability
بدست آید.
 پلات زیر، بیانگر هیستوگرام برای تصویر نویزی شماره 1 است:

\begin{figure}[h]
		\centering
		\includegraphics[scale=0.35]{assets/plot1.png}
		\caption{\textcolor{CustomAccent}{پلات هیستوگرام تصویر نویزی شماره 1}}
	\end{figure}
	
	این شکل، بیان می کند که تعداد پیکسل ها با مقدار نزدیک به صفر و مقدار نزدیک به 255 بسیار زیاد است. همچنین هیستوگرام احتمال قابل انتظار برای تصاویر نویزی با نوع نویز نمک فلفل به شکل زیر است:
	
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot2.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام قابل انتظار برای تصاویر نویزی نمک و فلفل}}
\end{figure}

\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} Asoke Nath: Image Denoising Algorithms: A Comparative Study of Different Filtration Approaches Used in Image Restoration
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}

با مقایسه شکل 1 و 2 می توان نتیجه گرفت که نویز تصویر شماره 1 از نوع نمک و فلفل می باشد. بنابراین، برای denoise کردن تصویر، بهترین گزینه، استفاده از فیلتر median می باشد. 
شایان ذکر است که در عملیات denoise کردن تصویر برای اطمینان بیشتر از نوع نویز، از انواع فیلترها استفاده شد که به شرح زیر هستند:

\begin{table}[ht]
	\centering
	\begin{latin}
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{Category} & \textbf{Filter Name} & \textbf{Function} \\
		\hline
		Smoothing Filters  & Box Filter              & \texttt{denoise\_box\_filter} \\
		& Gaussian Filter         & \texttt{denoise\_gaussian\_filter} \\
		\hline
		Statistical Filters & Median Filter           & \texttt{denoise\_median\_filter} \\
		& Max Filter              & \texttt{denoise\_max\_filter} \\
		& Min Filter              & \texttt{denoise\_min\_filter} \\
		\hline
		Advanced Filters   & Bilateral Filter        & \texttt{denoise\_bilateral\_filter} \\
		& Non-Local Means         & \texttt{denoise\_nl\_means} \\
		& Wavelet Filter          & \texttt{denoise\_wavelet\_filter} \\
		& Total Variation Filter  & \texttt{denoise\_total\_variation} \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{انواع فیلتر ها و توابع denoising به کار گرفته شده}
\end{table}


همانطور که از شکل 1 انتظار می رفت، بهترین عملکرد خروجی با استفاده از فیلتر میانه یا همان median بدست می آید. در نهایت، برای نهایی کردن بهترین خروجی با استفاده از فیلتر میانه، دو روش پیگیری شد:
\begin{enumerate}
	\item 
	استفاده از چند مرحله فیلتر median با ابعاد یکسان
	\item 
	استفاده از یک فیلتر median با کرنل بزرگتر
\end{enumerate}
روش اول، به طور کلی برای حفظ جزئیات تصویر مناسب تر است؛ زیرا هرگونه کرنل بزرگ  با ریسک از دست دادن جزئیات همراه است. از طرفی، ممکن است که همگرا شدن تصویر پس از اعمال چند بار فیلتر میانه، به کندی پیش رود و حتی برخی نویز ها در تصویر باقی بمانند که این مشکل، در روش دوم وجود ندارد. 

در نهایت، با توجه به مسئله که تنها نیاز است یک متن از تصویر استخراج شود (و حفظ سایر جزئیات دارای اهمیت کمتری است،) از روش دوم استفاده شد.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot4.png}
	\caption{\textcolor{CustomAccent}{شکل نهایی تصویر denoise شده}}
\end{figure}

\pagebreak

همچنین شایان ذکر است که برای درک بهتر نویز، از حوزه ی فرکانس نیز کمک گرفته شد
 \textsuperscript{[1]}  که بتوان نوع نویز را حدس زد و در نهایت با استفاده از فیلتر های notch و یا band-pass و یا band-reject از نویز تصویر کاست. شکل سوم بیانگر این موضوع است.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{assets/plot3.png}
	\caption{\textcolor{CustomAccent}{تصویر شماره 1 در حوزه فرکانس}}
\end{figure}

با توجه به magnitude تصویر در حوزه فرکانس، نمی توان نویز خاصی را قائل شد که نهایتا، همان فیلتر میانه که از هیستوگرام تصویر درک شده بود، استفاده شد.


\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} Digital Image Processing By Gonzalez 2nd Edition 2002, chapter 4.2
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}
%
%تبصره: برای کاهش حجم فایل ipynb برای پلاک کردن تصاویر، از figure هایی با ابعاد کوچک استفاده شده است که به ناچار تصاویر را sample down می کند؛ در عین حال، کلیت حل مسئله همچنان صحیح است. همچنین در تابع 
%
%\begin{latin}
%	\begin{lstlisting}[language=Python, caption={extract feature function}]
%def plote_images(images: list[np.ndarray], titles: list[str] = None, cmap: str = 'gray', figsize: tuple = (10, 5))
%...
%	\end{lstlisting}
%\end{latin}
%میتوان با انتخاب figsize بزرگتر، عملکرد هر کدام از فیلتر ها را به شکل واضح تری دید.
\pagebreak
\begin{itemize}
\item 
بخش دوم
\end{itemize}

برای این بخش باید تصویر 
$processed\_img\_part\_2.jpg$
اصلاح می شد. بدین منظور و در ابتدا برای تشخیص نویز، از انرژی و magnetude تصویر استفاده شد؛ زیرا تصویر کاملا پوشیده از نویز بود و پیش بینی نوع نویز را سخت می کرد. همچنین برای درک بهتر کلیت تصویر، با حذف فرکانس های بالا، یک تخمین از کلیت تصویر به دست آمده است. برای این منظور، پلات زیر رسم شده است:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{assets/plot9.png}
	\caption{\textcolor{CustomAccent}{پیش بینی نوع نویز در تصویر دوم}}
\end{figure}


با دقت کردن به لگاریتم power در پلات (شکل شماره 5) متوجه یک حلقه می شویم که با الگوی سینوسی نویز در تصویر در حوزه مکان تطابق دارد. برای درک بهتر این نویز، به طور مستقل برای تصویر در حوزه فرکانس magnitude و phase رسم شده است که به شکل زیر است:


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/plot10.png}
	\caption{\textcolor{CustomAccent}{تصویر دوم در حوزه فرکانس}}
\end{figure}

که ایده اولیه را تایید می کند. بدین منظور، تنها و به سادگی با ساختن یک فیلتر band-reject در حوزه فرکانس، این مشکل حل شده و تصویر نهایی ساخته می شود.

\pagebreak


\begin{itemize}
	\item 
	بخش سوم
\end{itemize}
برای بخش سوم از پازل، باید تصویر اصلی را از 5 زیر تصویر reconstruct می کردیم. بدین منظور، تصاویر در ابتدا و در کنار یکدیگر plot شده اند:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/plot5.png}
	\caption{\textcolor{CustomAccent}{زیرتصاویر بخش سوم پازل}}
\end{figure}


همچنین ابعاد هر کدام از تصاویر در جدول زیر بیان شده است:

\begin{table}[h!]
	\centering
	\begin{latin}
	\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Image File} & \textbf{Width (px)} & \textbf{Height (px)} \\
		\hline
		processed\_img\_part\_3\_Level\_0.jpg & 1796 & 1201 \\
		processed\_img\_part\_3\_Level\_1.jpg & 898  & 601  \\
		processed\_img\_part\_3\_Level\_2.jpg & 449  & 301  \\
		processed\_img\_part\_3\_Level\_3.jpg & 225  & 151  \\
		processed\_img\_part\_3\_Level\_4.jpg & 113  & 76   \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{ابعاد زیر تصاویر در بخش سوم پازل}
\end{table}

با توجه به جدول شماره 2 که بیانگر ابعاد پازل است، میتوان متوجه شد که در هر مرحله با تقریب هم طول و هم عرض تصویر نصف می شود. این موضوع، وجود نوعی pyramid را در ذهن تداعی می کند \textsuperscript{[1]}.
 این موضوع، در زیربخش سوم فصل هفتم کتاب گونزالس
 \textsuperscript{[2]}
  به این شکل آمده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.3]{assets/pyramids.png}
	\caption{\textcolor{CustomAccent}{انواع pyramid ها: کتاب گونزالس، زیربخش سوم فصل هفتم}}
\end{figure}




\vfill
\hline
\begin{LTR}
	\begin{latin}
		\begin{center}
			\begin{minipage}{0.9\linewidth}
				\small % or \footnotesize
				\textsuperscript{[1]} medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \\
				\textsuperscript{[2]} Digital Image Processing By Gonzalez 2nd Edition 2002, chapter 7.3
			\end{minipage}
		\end{center}
	\end{latin}
\end{LTR}
 

\pagebreak

برای درک بهتر هرم، هیستوگرام احتمال برای هر کدام از زیر تصاویر رسم شده است:


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/plot6.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام در هرم}}
\end{figure}

نمودار هیستوگرام نرمال‌شده‌ی هرم، توزیع آماری مقدارهای باقیمانده در هر سطح از هرم را نمایش می‌دهد. در فرآیند ساخت هرم، هر تصویر در یک سطح با نسخه‌ی بزرگ‌ نمایی ‌شده ‌ی تصویر سطح بعدی کم می‌شود، و نتیجه این اختلاف، تصویر باقیمانده‌ای است که تنها حاوی اطلاعات لبه‌ ها، جزییات کوچک است. برای نمایش بهتر این اطلاعات، از یک آفست استفاده شده و همچنین نرمال سازی انجام شده است. در تایید این موضوع، از تبدیل به حوزه فوریه و نمایش فاز هر کدام از زیر تصاویر نیز استفاده شده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/plot7.png}
	\caption{\textcolor{CustomAccent}{هیستوگرام در هرم}}
\end{figure}
 همانطور که مشخص است، لبه های کوچک در سطوح بالا، دارای فاز یکنواخت تری هستند و هرچه به لایه های پایین تر می رویم، این یکنواختی کمتر می شود و تغییرات فرکانس وضوح می یابند.

با دقت به این هیستوگرام، (و همچنین زیرتصاویر ارائه شده در شکل پنجم) میتوان نتیجه گرفت که هرم از نوع لاپلاسی است؛ هر مرحله از downsample شدن تصویر و محاسبه اختلاف با لایه قبلی محاسبه می شود که برای ساختن تصویر اصلی، کافیست معکوس این کار را انجام دهیم.


\pagebreak

برای درست کردن تصویر، در ابتدا تلاش شد که با طی کردن فرایند به شکل معکوس، تصویر اصلی ساخته شود، اما تصویر خروجی شامل کیفیت مناسب نبود. بدین منظور، از تابع resize از کتابخانه cv2 استفاده شد که به صورت خطی تصویر را تغییر سایز می دهد. همچنین، برای بهبود نهایی، مقادیر grayscale به uint8 تغییر یافته اند؛ به عبارتی، مقادیر قبلی سطوح خاکستری با این کار، به بازه (0, 255) گسترش یافتند که باعث بهبود کنتراست شد.
تصویر نهایی ساخته شده نیز در شکل 9 آمده شده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{assets/plot8.png}
	\caption{\textcolor{CustomAccent}{تصویر نهایی ساخته شده از زیرتصاویر}}
\end{figure}


\pagebreak
\section{پروژه دوم: تصاویرنویزی/غیرنویزی}
در این پروژه، هر دو روش یادگیری عمیق و بینایی ماشین کلاسیک پیاده سازی شده است. در ابتدا به تفصیل، روش یادگیری عمیق توضیح داده می شود:

\section{یادگیری عمیق در پروژه دوم}


در ابتدا، برای پیاده سازی سیستم تشخیص نویز ها، این نیاز دیده میشد که دیتاست های در اختیار قرار گرفته ، دیتاست های کوچکی هستند و برای روش های ml و یا dl مناسب نیستند. به گونه ای که حتی با augment کردن داده ها و پیاده سازی بر روی مدل های pre-trained و با fine tune کردن آنها نیز، کفایت نمیکرد.  بنابراین، با بررسی دیتاست های قرار داده شده کشاورزی که از نوع برگ درختان هستند، دیتاست های کاندیدا از وبسایت kaggle به شرح زیر هستند:
\begin{enumerate}
	\begin{LTR}
		\begin{latin}
			\item https://www.kaggle.com/datasets/ichhadhari/leaf-images
			\item https://www.kaggle.com/datasets/mdwaquarazam/agricultural-crops-image-classification/data
			\item https://www.kaggle.com/datasets/alexo98/leaf-detection
		\end{latin}
	\end{LTR}
\end{enumerate}

که طبق بررسی انجام شده، بهترین و مشابه ترین دیتاست، مربوط به دیتاست leaf-detection است. 
دقت شود که این موضوع که دیتاست ها باید برای استفاده این پروژه به شکل کاملی شخصی سازی شوند (به عنوان مثال، نویز به تصاویر اضافه شود) کاملا واضح است و از ابتدا صرفا به دنبال دیتاست هایی صرفا با زمینه مرتبط بودم و سپس دیتاست ها را به شکل مناسبی برای استفاده از این پروژه شخصی سازی کردم. مجددا تاکید میشود که دیتاست انتخاب شده، صرفا انواع برگ های گوناگون بوده است و هیچ هدفی از نویز/دینویز کردن تصاویر در این دیتاست دنبال نشده است. 

بررسی دیتاست آورده شده:

با توجه به این که این دیتاست، صرفا شامل تصاویری از برگ های 10 نوع درخت هندی هستند، بدون توجه به لیبل های آن برگ ها، و صرفا با در نظر گرفتن همه آنها از یک نوع، (همگی را به شکل یکسان و «برگ» در نظر گرفتم) به آنها انواع گوناگونی از نویز ها پیاده سازی کردم. در ابتدا، نویزهای تکی، یعنی :

سپس انواع نویز های دو تایی (تمامی جایگشت ها لحاظ نشده است؛ به علت محدودیت پردازشی گوگل کولب به 16 گیگ حافظه رم، بیش از این نوع نمیتوان جایگشت های مختلفی از نویز در نظر گرفت):

\pagebreak

\begin{table}[h]
	\centering
	\begin{latin}
	\begin{tabular}{|c|c|l|}
		\hline
		\textbf{No.} & \textbf{Combinations} & \textbf{Noise Type} \\
		\hline
		1 & 1 & Gaussian \\
		\hline
		2 & 1 & Salt \& Pepper \\
		\hline
		3 & 1 & Poisson \\
		\hline
		4 & 1 & Speckle \\
		\hline
		5 & 1 & Uniform \\
		\hline
		6 & 2 & Gaussian + Salt \& Pepper \\
		\hline
		7 & 2 & Gaussian + Poisson \\
		\hline
		8 & 2 & Gaussian + Speckle \\
		\hline
		9 & 2 & Gaussian + Uniform \\
		\hline
		10 & 2 & Salt \& Pepper + Speckle \\
		\hline
		11 & 2 & Salt \& Pepper + Uniform \\
		\hline
		12 & 2 & Poisson + Speckle \\
		\hline
		13 & 2 & Poisson + Uniform \\
		\hline
		14 & 2 & Speckle + Uniform \\
		\hline
		15 & 3 & Gaussian + Salt \& Pepper + Speckle \\
		\hline
		16 & 3 & Gaussian + Poisson + Uniform \\
		\hline
		17 & 3 & Salt \& Pepper + Speckle + Uniform \\
		\hline
	\end{tabular}
	\end{latin}
	\caption{لیست انواع نویز های پیاده شده}
\end{table}
	

\pagebreak


\section{پروژه سوم: ادغام تصاویر پزشکی}
در این پروژه، ابتدا پیاده‌سازی با استفاده از روش‌های کلاسیک انجام شده و جزئیات مربوط به آن به‌طور کامل توضیح داده شده است. گام مشترک میان هر دو روش، پروفایل دیتا است.
در ابتدا باید بر روی دیتاست عملیات پروفایل کردن دیتا انجام میشد که بررسی شود دیتاست تصاویر به شکل ct (که به شکلی هستند که استخوان ها را به رنگ سفید نمایش می دهند) با تصاویر mri از نظر سایز، فرمت، طول و عرض تصویر و نسبت طول به عرض با یکدیگر تطابق دارند یا خیر. بدین منظور، نتیجه این پروفایل کردن در زیر قابل مشاهده است:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{assets/3.2.png}
	\caption{\textcolor{CustomAccent}{نتیجه پروفایل دیتا}}
\end{figure}
(شایان ذکر است که شاید گمان شود که برای این دیتاست کوچک، نیازی به پروفایل کردن دقیق دیتا نبوده و صرفا یک مشاهده کوچک بر روی 8 زوج عکس، کفایت میکند، اما روش ارائه شده برای هرتعداد جفت عکس ارائه شده قابل اجراست و مرحله ابتدایی الزامی هر پروژه ای محسوب میشود.)

\section*{راه حل با روش های بینایی کلاسیک}

همانطور که در اسلاید های درسی داشتیم:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{assets/3.1.png}
	\caption{\textcolor{CustomAccent}{نحوه ادغام دو نوع تصویر مختلف}}
\end{figure}

باید pyramid هایی از هر دو نوع تصویر تهیه کنیم. در ابتدا ویژگی هایی که هر سطح از این pyramid ها شامل می شوند، به شکل زیر بیان می شود:
\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{سطح} & \textbf{اندازه تصویر} & \textbf{فرکانس} & \textbf{ویژگی‌های استخراج‌شده} \\
		\hline
		سطح ۰ & اندازه کامل & فرکانس بالا & جزئیات ریز (لبه‌ها، بافت، نویز) \\
		\hline
		سطح ۱ & نصف اندازه & فرکانس متوسط & لبه‌های بزرگ‌تر، اشکال \\
		\hline
		سطح ۲ & یک‌چهارم اندازه & فرکانس پایین & نواحی صاف، روشنایی کلی \\
		\hline
		سطح N (بالا) & بسیار کوچک & فرکانس بسیار پایین & ساختار کلی، سایه‌روشن نرم \\
		\hline
	\end{tabular}
	\caption{ساختار سطوح در هرم تصویری}
\end{table}
این قانون در رابطه با هر دو نوع هرم گوسی و لاپلاسی صدق می کند. (البته این دو هرم در نوع نمایششان با یکدیگر متفاوت هستند) .
در نهایت، مورد دیگری که باید بحث شود نحوه ادغام است که به این شکل چندین روش می توان به کار برد:
\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Fusion Rule} & \textbf{عملکرد} & \textbf{ویژگی‌های حفظ‌شده} \\
		\hline
		Average (mean) & ترکیب برابر دو تصویر & اطلاعات متعادل \\
		\hline
		Min & انتخاب مقدار کمینه هر پیکسل & ویژگی‌های تیره \\
		\hline
		Max & انتخاب مقدار بیشینه هر پیکسل & ویژگی‌های روشن \\
		\hline
		Max-Abs & انتخاب پیکسلی با بیشترین قدرمطلق & لبه‌های قوی با فرکانس بالا \\
		\hline
		Energy-Max & انتخاب پیکسل از تصویری با انرژی محلی بالاتر & بافت، واریانس محلی \\
		\hline
		Saliency-Based & انتخاب پیکسل با لبه بیشتر & ساختارهای برجسته \\
		\hline
		Weighted (static) & میانگین وزنی با وزن‌های دستی & تاثیر قابل تنظیم \\
		\hline
		Weighted (adaptive) & وزن‌دهی بر اساس انرژی & ترکیب تطبیقی \\
		\hline
		PCA-Based & تقسیم تصویر به مؤلفه‌های اصلی & ساختارهای همبسته \\ 
		\hline
	\end{tabular}
	\caption{قوانین مختلف ادغام تصویر و ویژگی‌های حفظ‌شده}
\end{table}

پارامتر بعدی که باید بررسی شود، عمق این pyramid ها می باشد. به طور کلی، با توجه به اینجا:
\begin{latin}
	\begin{itemize}
		\item \href{https://ieeexplore.ieee.org/document/1095851}{The Laplacian Pyramid as a Compact Image Code}
	\end{itemize}
\end{latin}
اشاره شده است که برای تهیه هر هرمی، میتوان از الگوی زیر تبعیت کرد:
\[
\text{max\_levels} = \left\lfloor \log_2\left(\min(H, W)\right) \right\rfloor
\]
که با توجه به تصویر ورودی 256 * 256 می توان هرم را به حداکثر 8 سطح تقسیم کرد. 
اکنون 	


\pagebreak
\section*{راه حل با روش های یادگیری عمیق}

به‌عنوان مطالعه ی تکمیلی، روش‌های مبتنی بر یادگیری عمیق را نیز بررسی کردم. به طور خاص مقاله ای که مطالعه کردم در اینجا قرار دارد:

\begin{latin}
\begin{itemize}
\item \href{https://arxiv.org/html/2506.15218v1}{DM-FNet: Unified multimodal medical image fusion via diffusion process-trained encoder-decoder}
\end{itemize}
\end{latin}
 
 روش های کلاسیکی که پیاده سازی شده است، صرفا شامل ساختار های هرم بودند و در نهایت در پیشرفته ترین مدل های خود، از ویولت استفاده می کردند که مشکل بزرگی داشتند:
 یا تصویر نهایی به شکل زیادی smooth می شود و یا جزئیات هر دو منبع ورودی را نمیتوان نگه داشت.
 این دو مورد انگیزه هایی بودند که برای حل این مسئله شبکه های عمیق سوق داده شده اند.
 
 
 مرحله‌ی اول بر پایه‌ی DDPM طراحی شده است؛ مدلی که هدف آن، یادگیری معکوس‌سازی یک forward noise process به‌صورت مرحله‌به‌مرحله است. برخلاف کاربردهای معمول که در آن‌ها تصویر نهایی از نویز تصادفی تولید می‌شود، در این‌جا DDPM به‌عنوان ابزاری برای استخراج  map feature ‌های با کیفیت بالا و در مقیاس‌های مختلف از هر نوع تصویر MRI و CT به کار گرفته شده است.
 
 در این چارچوب، برای هر مدالیته یک diffusion model مبتنی بر UNet به‌صورت جداگانه آموزش داده شده است. هدف این مرحله بازسازی تصویر نیست، بلکه embedding کردن اطلاعات هر مدالیته در یک فضای بازنمایی عمیق و سلسله‌مراتبی است که بتواند ساختارهای مهم تصویر را به‌خوبی نمایش دهد.
 
 ویژگی‌هایی که در این مرحله استخراج می‌شوند، نقش نوعی سوپروایزر را برای نوع تصویر خود ایفا می‌کنند؛ به این معنا که مدل MRI در شناسایی ویژگی‌های مرتبط با soft tissue تخصص دارد، در حالی که مدل CT تمرکز بیشتری روی ساختارهای استخوانی دارد.
 
 در مجموع، این مرحله مانند یک preprocessor هوشمند عمل می‌کند که به‌جای استفاده از feature extractorهای سطحی و سنتی، از encoderهایی بهره می‌گیرد که با فرایند diffusion آموزش دیده‌اند و می‌توانند فیچر ‌هایی دقیق ارائه دهند.
 
 پس از استخراج deep feature
 ها از هر دو مدالیته، مرحله‌ی دوم با نام 
 \begin{latin}
DFFM (Diffusion Feature Fusion Model) 
 \end{latin}
 
 
 وظیفه‌ی ادغام واقعی اطلاعات را بر عهده می‌گیرد. برخلاف روش‌های ساده‌ای مانند میانگین‌گیری یا روی هم قرار دادن مستقیم ویژگی‌ها، در این‌جا فرایند fusion با استفاده از دو ماژول مجزا و هدفمند انجام شده است.
 

بخشی از کدهایی که از این مقاله که شامل معماری مدل اصلی بود در فایل پایتونی ام قرار دادم.
قصد داشتم از این مدل یک inference انجام دهم تا با روش های کلاسیک مقایسه کنم؛ اما در نهایت تنها به بیان مطالعات، درک و برداشت خود از این نوع شبکه‌های عمیق بسنده کردم؛ زیرا  یتاست‌های غنی و همچنین مدل‌ ها و مقالات متعددی وجود دارند که بر روی همین زمینه فعالیت کرده اند و منبع خوبی برای یادگیری هستند.

\pagebreak
\section{پروژه چهارم: والدو}
برای این پروژه، سه شیوه اصلی پیاده شد:
\begin{enumerate}
	\item  با استفاده از cross-correlation
	\item استفاده از هرم و پیاده سازی multi-resolution-correlation
	\item تهیه دیتاست و پیاده سازی با شبکه عصبی عمیق
	
	به تفصیل هر کدام از آنها در ادامه توضیح داده می شود:
	
\end{enumerate}


\section*{پیاده سازی با کورولیشن}
در این روش، در ابتدا کانفیگ های مختلف به ازای درجه های چرخیدن
40, 90, 135, 180, 225, 270, 315, 360 درجه و به ازای میزان اسیکیل
$
 0.8,\, 0.9 \, , 1.0,\,  1.1, \, 1.2,\,  1.3,\,  1.4,\, 1.5$
 ساخته شد که در مجموع 64 کانفیگ گوناگون را می سازند. 
  
 \begin{figure}[h]
 	\centering
 	\includegraphics[scale=0.4]{assets/4.1.png}
 	\caption{\textcolor{CustomAccent}{جهت چرخش در تصویر ورودی والدو}}
 \end{figure}
 
 
سپس به کمک کتابخانه cv2 و با استفاده از تابع cross-correlation به ازای تصویر ورودی، انواع این 64 کانفیگ به ورودی اعمال شد.
در ابتدا، به ازای ورودی والدو و تصویر زمینه رنگی rgb ، تست گرفته شد که نتیجه خروجی مطلوب است و تمامی والدو ها به درستی تشخیص داده شده اند. (برای میزان شباهت باید بر روی متغیر ترشولد حداقل شباهت tuning انجام میشد که پس از tuning خروجی درست شد.)

سپس برای همین متد ارائه شده، و با ورودی تصاویر زمینه و والدو grayscle شده نیز همین عملیات انجام شد و خروجی دقیقا مشابه و البته با صرف یک سوم زمان به ازای ورودی رنگی انجام شد.



\begin{figure}[ht]
	\centering
	\begin{minipage}[t]{0.42\textwidth}
		\centering
		\includegraphics[width=\linewidth]{assets/4.2.png}
		\caption{\textcolor{CustomAccent}{به ازای ورودی تصویر رنگی}}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{0.42\textwidth}
		\centering
		\includegraphics[width=\linewidth]{assets/4.3.png}
		\caption{\textcolor{CustomAccent}{به ازای ورودی تصویر خاکسترس}}
	\end{minipage}
	\vspace{1em}
\end{figure}

و اما برای مقایسه زمان پیاده سازی:
\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf\textbf{نوع ورودی} & \textbf{زمان مصرف شده} \\
		\hline
		به ازای ورودی خاکستری & $15.819602489471436$ \\
		\hline
	به ازای ورودی رنگی & $5.439622163772583$ \\
		\hline
	\end{tabular}
	\caption{زمان صرف شده برای پیدا کردن والدو}
\end{table}

که به طرز واضحی نشان دهنده سرعت خروجی دادن یک سوم شده است و همان کیفیت نیز حفظ شده است. 

\section*{روش دوم برای کاهش زمان مصرف شده : multi-reslution}

 \begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/4.5.png}
	\caption{\textcolor{CustomAccent}{پیدا کردن والدو به کمک روش چند رزولوشنی طبق اسلاید های درسی}}
\end{figure}

در این روش، به جای مقایسه الگوی کامل با تمام موقعیت‌های ممکن در تصویر اصلی با وضوح کامل، از هرم‌های تصویری استفاده می‌شود تا تطبیق به‌صورت تدریجی و از وضوح پایین به بالا انجام شود.

فرآیند با ساخت هرم‌هایی از تصویر ورودی و الگو آغاز می‌شود. هر سطح از هرم، نسخه‌ای کوچک‌تر (پایین‌نمونه‌گیری‌شده) از سطح قبلی است که عرض و ارتفاع آن به نصف کاهش می‌یابد. برای مثال، یک تصویر ۱۰۲۴×۱۰۲۴ در سطح ۱ به ۵۱۲×۵۱۲ و در سطح ۲ به ۲۵۶×۲۵۶ تبدیل می‌شود. تطبیق از پایین‌ترین سطح هرم (مثلاً سطح ۲) آغاز می‌شود؛ جایی که تصویر کوچک‌تر است و پردازش سریع‌تر انجام می‌گیرد. در این سطح، یک جستجوی کامل انجام شده و ممکن است تعداد زیادی تطبیق تقریبی پیدا شود — مثلاً حدود ۱۰۰۰ مورد.

این تطبیق‌های تقریبی در سطح بالاتر هرم (مثلاً سطح ۱) با دقت بیشتر بررسی و اصلاح می‌شوند. اما به جای بررسی کل تصویر، فقط نواحی اطراف تطبیق‌های قبلی بررسی می‌گردند. این کار به‌طور چشمگیری تعداد مقایسه‌ها را کاهش می‌دهد. بسیاری از تطبیق‌های ضعیف در این مرحله حذف می‌شوند و ممکن است تعداد کاندیدها از ۱۰۰۰ به ۲۰۰ مورد کاهش یابد.

در نهایت، در بالاترین سطح هرم (سطح ۰، یعنی تصویر با وضوح کامل)، تطبیق دقیق فقط در نواحی مربوط به آن ۲۰۰ کاندیدای فیلترشده انجام می‌شود، نه در کل تصویر. در این مرحله، تنها تطبیق‌ های قوی و دقیق باقی می‌مانند. 

این فرآیند پالایش سلسله‌مراتبی همان چیزی است که تطبیق مبتنی بر هرم را بسیار قدرتمند می‌سازد. در واقع، بار محاسباتی اصلی به سطوح پایین‌تر منتقل می‌شود که تطبیق در آن‌ها بسیار سریع‌تر است، و تنها برای نواحی مناسب در وضوح بالا وقت صرف می‌شود. نتیجه این است که سیستمی با دقت بالا ولی سرعت بسیار بیشتر نسبت به روش تطبیق کلی در وضوح کامل خواهیم داشت.

در نهایت، استفاده از این روش نیازمند tune کردن تعداد لایه ها نیز می باشد. نتیجه تیون کردن تعداد لایه ها به این شکل بود که هرچه لایه ها را بیشتر میکردم، تعداد مواردی که تشخیص داده میشد نیز بیشتر میشد و باید ترشولد را نیز بالاتر میبردم. این بالاتر بردن ترشولد باعث میشد والدو هایی که روتیت شده بودند (که به علت خاصیتی که از کیفیت والدو اصلی به دلیل روتیت شدن برخوردار نبودند) قابل تشخیص نباشند. بنابراین تعداد لایه ها را محدود به 3 لایه کردم.

همچنین، طبق بررسی هایم، هر چقدر تعداد لایه ها بیشتر باشد، سرعت خروجی دادن نیز بیشتر میشد. (البته مسلما این رابطه تا بینهایت لایه تاثیر گذار نیست، اما تا 6 لایه تاثیر خودش را نشان میداد.) اما به این دلیل که کیفیت خروجی را کاهش میداد، در نهایت، به همان سه لایه بسنده کردم. همچنین از نظر سرعت نیز، به ازای ورودی 64 کانفیگ توضیح داده شده، چنین است:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf\textbf{نوع ورودی} & \textbf{زمان مصرف شده} \\
		\hline
		به ازای ورودی خاکستری & $6.921$ \\
		\hline
		به ازای ورودی رنگی & $19.6$ \\
		\hline	
	\end{tabular}
	\caption{زمان صرف شده برای پیدا کردن والدو با هرم رزولوشن های مختلف}
\end{table}

که البته نسبت به روش اولیه افزایش یافته است. دلیل آن هم میتوان در این یافت که تعداد لایه ها محدود است و پیشرفت زمانی خودش را نمیتواند نشان دهد. همچنین این متد، نیازمند تیونینگ بود که توضیح داده شد. 

\section*{یادگیری عمیق در پیدا کردن والدو}

\begin{latin}
	\begin{itemize}
		\item \href{https://medium.com/analytics-vidhya/finding-waldo-using-a-simple-convolutional-neural-network-1604cb4d2e55}{Finding “Waldo” using a simple Convolutional Neural Network}
	\end{itemize}
\end{latin}

با توجه به این صفحه مدیوم، در ابتدا یک دیتاست ساختم. دیتاست ساخته شده ام به این شکل عمل میکرد که در ابتدا یک سمپل 200*200 از تصویر زمینه میگرفت و بعد با یک درصد رندومنس والدو را بر روی آن بر روی یک نقطه رندوم و با یک کانفیگ رندوم قرار میداد.

سپس بر روی یک شبکه عصبی pre-train شده از نوع mobile-net ، هم classification به معنی بررسی حضور یا عدم حضور والدو و هم regression برای پیدا کردن موقعیت والدو پیاده سازی شد. نتیجه این مدل این شد که حتی با کمترین ترشولد دقت نیز، تنها 3 موقعیت تشخیص داده شده بود که همان هم خیلی رندوم بودند و اصلا والدو نبودند.

سپس با بررسی بیشتر، دلیل این موضوع را به کم بودن دیتای والدوی واقعی یافتم. بدین منظور دیتاست جدیدی ساختم که 90 درصد دیتا والدو حاضر بود و در بقیه نبود و سپس فاین تیون کردن را انجام دادم. این مدل در پیدا کردن والدو، همانطور که انتظار میرفت، بیشتر ریسک میکرد، و تعداد بیشتری کاندید نشان میداد، اما باز هم والدوی واقعی هیچی پیدا نکرد.

در نهایت دلیل اصلی عدم موفقیت این دو دیتاست و مدل ها را پیدا کردم: این که باید تصویر زمینه ثابت و برابر با کل تصویر اصلی باشد. باید ذکر کنم که انگیزه ام از شیوه قبلی تنظیم دیتاست، این بود که وقتی کل زمین را یکجا به مدل میدهیم، به نوعی یادگیری واقعی انجام نشده و به سمت ورودی بایاس می شویم. اما با خواندن مقاله، دیدم که ظاهرا همین نوع که کل تصویر زمینه اصلی را استفاده کنیم، روش استانداردی است. بدین منظور، دیتاست جدیدی  ساختم که والدو ها را به شکل رندوم مشابه قبلی در تصویر patch میکرد، اما این تصویر، به جای سمپل های رندوم 200*200 از تصویر زمینه اصلی، کل تصویر زمینه اصلی بود.

نتیجه این دیتاست اخری، این شد که گویا واقعا یادگیری انجام میشد، شاخص loss از نزدیک به 100k به 1000 رسید، که در همین جا متوقف شد. به دلیل سبک بودن بیش از حد مدل من، و همچنین کم بودن دیتای ورودی (تنها 500 تصویر ساختم که همگی شامل تصویر اصلی بودند.) به علت محدودیت حافظه گوگل کولب (همان 500 تصویر، نزدیک به 7 گیگابایت رم از 12 گیگ را اشغال کرده بوند)، مدل همچنان loss بالایی داشت که عدد 1000 همچنان نمیتوانست جای والدو را به خوبی پیدا کند. در صورتی که میتوانستم از مدلی سنگین تر و همچنین دیتاستی غنی تر استفاده کنم، مسلما به پاسخ بهتری میرسیدم، اما با همین مدل نهایی، یک والدوی درست (و تعداد زیادی موارد نامربوط) تشخیص داده شد.

 \begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{assets/4.4.png}
	\caption{\textcolor{CustomAccent}{والدو با شبکه عصبی سوم}}
\end{figure}

همچنین شایان ذکر است مدت زمان inference این مدل سومی، حدود 17 ثانیه طول میکشید که از روش های کلاسیک نیز بیشتر است. 


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\pagebreak
	
	در ابتدا، به کمک کتابخانه 
	$cv2$
	تابع زیر را برای دریافت فیچرها تکمیل کردیم. 
	
	\begin{latin}
		\begin{lstlisting}[language=Python, caption={extract feature function}]
			def extract_features(image_path)
			# input is an image and the ouput is an array of features.
		\end{lstlisting}
	\end{latin}
	
	


	\begin{figure}[ht]
		\centering
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{another caption}}
		\end{minipage}
		\hfill
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{caption new}}
		\end{minipage}
		\vspace{1em}
		\hfill
		\begin{minipage}[t]{0.32\textwidth}
			\centering
			\includegraphics[width=\linewidth]{assets/template.png}
			\caption{\textcolor{CustomAccent}{caption new}}
		\end{minipage}
		\vspace{1em}
	\end{figure}
	
	
	
\clearpage
\section*{منابع}

\begin{LTR}
	\begin{latin}
		\begin{enumerate}[left=0pt,labelsep=5pt,itemsep=0pt,parsep=0pt,topsep=0pt]
			\item Image Denoising Algorithms: A Comparative Study of Different Filtration Approaches Used in Image Restoration.  \url{https://ieeexplore.ieee.org/abstract/document/6524379/}
			\item Digital Image Processing By Gonzalez 4th  \url{https://elibrary.pearson.de/book/99.150005/9781292223070}
			\item Automatic identification of noise in ice images using statistical features \url{https://www.researchgate.net/figure/Simple-pattern-classifier-to-identify-noise-types-of-Gaussian-Speckle-and -Salt-Pepper_tbl1_258714501}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			
			
			% below are dummy
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			\item medium: A Beginners Guide to Computer Vision (Part 4)- Pyramid \url{https://medium.com/analytics-vidhya/a-beginners-guide-to-computer-vision-part-4-pyramid-3640edeffb00}
			
		\end{enumerate}
	\end{latin}
\end{LTR}



\end{document}
